


# ğŸ± **StealthKitty - Projet Robot Chat**  

 <img src="https://megabase.eduniversal.com/uploads/school/1155/logo.jpg?v=c7e3965d14625a3e4b5662bd550d93e0" alt="Logo ENSEA" width="30"/> ![STM32](https://img.shields.io/badge/STM32-Embedded-blue?style=for-the-badge&logo=stmicroelectronics)  
[![ENSEA](https://img.shields.io/badge/ENSEA-3A--ESE-green?style=for-the-badge&logo=https://upload.wikimedia.org/wikipedia/fr/8/82/Logo_ENSEA.svg)](https://www.ensea.fr)
![Status](https://img.shields.io/badge/Status-Finished-orange?style=for-the-badge)  


---

## ğŸ“œ **Description**  
StealthKitty est un projet de **systÃ¨me embarquÃ© innovant** basÃ© sur un **STM32**.  
ğŸ¯ **Objectif :** DÃ©velopper plusieurs robots capables de se dÃ©placer sur une table sans bordure.  

- ğŸ¾ Un robot est dÃ©signÃ© comme chat et doit attraper un autre robot, qui devient alors le nouveau chat.  

Ce projet est rÃ©alisÃ© dans le cadre de la derniÃ¨re annÃ©e de la filiÃ¨re **Ã©lectronique et systÃ¨mes embarquÃ©s (ESE)** de l'ENSEA.

### **Les contributeurs :**  
- ğŸ‘¨â€ğŸ’» **Vincent LAKHMECHE**  
- ğŸ‘¨â€ğŸ’» **Mohamed Rafik CHAIR**  
- ğŸ‘¨â€ğŸ’» **Meziane Ameur**  
- ğŸ‘¨â€ğŸ’» **Karim JERJOUB**  
![image](https://github.com/user-attachments/assets/0b8a3520-2e76-4162-91c8-48ae93badee7)

![image-20250114141624020](./assets/image-20250114141624020.png)

---

## ğŸ“š **Table des matiÃ¨res**  A REECRIRE
1. [ğŸ“– Contexte](#-contexte)  
2. [âœ¨ FonctionnalitÃ©s](#-fonctionnalitÃ©s)  
3. [ğŸ”§ MatÃ©riel utilisÃ©](#-matÃ©riel-utilisÃ©)  
4. [ğŸ“ Architecture](#-architecture)  
5. [ğŸš€ Utilisation](#-utilisation)  
6. [ğŸ‘¥ Auteurs](#-auteurs)  
7. [ğŸ“„ Licence](#-licence)  

---

## ğŸ“– **Contexte**  
Ce projet s'inscrit dans le cadre de la formation 3A Ã  l'ENSEA.  
ğŸ¯ L'objectif est de concevoir un systÃ¨me embarquÃ© complet, depuis la conception Ã©lectronique jusqu'Ã  l'implÃ©mentation logicielle.

---

## âœ¨ **FonctionnalitÃ©s**  
- ğŸ›¡ï¸ **DÃ©tection de bords** via des capteurs ToF.  
- ğŸ”„ **Communication entre robots** pour synchronisation.  
- ğŸ¯ **Algorithme de poursuite et d'Ã©vitement.**  
- âš™ï¸ **Gestion des moteurs**  

---

## ğŸ”§ **MatÃ©riel utilisÃ©**  
- **STM32G431RB** : MicrocontrÃ´leur principal.  
- **Capteurs ToF** : DÃ©tection des bordures.  
- **LiDAR** : Cartographie et dÃ©tection d'autres robots.  
- **AccÃ©lÃ©romÃ¨tre (ADXL343)** : DÃ©tection des chocs pour changer de rÃ´le (Chat/Souris).  
- **Environnement de dÃ©veloppement :** STM32CubeIDE.  

---

## ğŸ“ **Architecture**  
### **SchÃ©ma architectural**  
![image](https://github.com/user-attachments/assets/0f7c4c1b-3890-4360-bbe3-213a3acfd5ad)

Ce schÃ©ma ne dÃ©taille pas que chaque moteur a sa propre pwm et son driver propre Ã©galement.

## Explication du fonctionnement du systÃ¨me

1. **âš¡ Alimentation principale**
   - La **batterie NiMH 7.2V 1.3Ah** alimente l'ensemble du systÃ¨me. Elle est connectÃ©e Ã  des rÃ©gulateurs de tension pour fournir les diffÃ©rentes tensions nÃ©cessaires aux composants :
     - **MP1475S** : RÃ©gulateur 5V pour alimenter les moteurs et certains capteurs.
     - **BU33SD5WG-TR** : RÃ©gulateur 3.3V pour alimenter le microcontrÃ´leur STM32G431, l'accÃ©lÃ©romÃ¨tre et le LiDAR.

2. **ğŸ–¥ï¸ MicrocontrÃ´leur principal - STM32G431**
   - Le **STM32G431** gÃ¨re toute la logique du robot et communique avec les diffÃ©rents composants via des bus tels que SPI, UART, I2C et PWM.
   - Il est reliÃ© Ã  un **quartz 16 MHz** pour la gestion de l'horloge systÃ¨me et dispose d'un connecteur **SWD** pour la programmation et le dÃ©bogage.

3. **ğŸ” Capteurs**
   - **Capteurs ToF** : UtilisÃ©s pour dÃ©tecter les bords ou les chutes du robot.
   - **ADXL343 (AccÃ©lÃ©romÃ¨tre)** : DÃ©tecte les impacts ou les tapotements, utilisÃ© pour dÃ©tecter les collisions avec d'autres robots, et connectÃ© au bus **SPI**.
   - **LiDAR YDLIDAR X4** : Permet de dÃ©tecter les obstacles Ã  l'aide de la communication **UART** pour transmettre les donnÃ©es de distance et d'angle.

4. **âš™ï¸ ContrÃ´le des moteurs**
   - **ZXBM5210-SP-13 (Driver de moteur)** : UtilisÃ© pour contrÃ´ler la direction et la vitesse des moteurs Ã  l'aide de signaux **PWM**. Le microcontrÃ´leur STM32 contrÃ´le les moteurs via le driver pour ajuster la vitesse et la direction du robot.

5. **ğŸŒŸ Indicateurs d'Ã©tat (LEDs)**
   - Les **LEDs** servent d'indicateurs pour visualiser l'Ã©tat du robot, par exemple, lorsqu'il est en marche ou lorsqu'il dÃ©tecte un obstacle.

### DÃ©tails des principaux outils utilisÃ©s

1. **Communication avec l'accÃ©lÃ©romÃ¨tre (ADXL343)**
   - Utilisation du protocole **SPI** pour lire les donnÃ©es des axes X, Y et Z.
   - DÃ©tection des chocs (taps) causÃ©s par des collisions avec d'autres robots.

2. **ContrÃ´le des moteurs avec le driver ZXBM5210**
   - GÃ©nÃ©ration de signaux **PWM** pour rÃ©guler la vitesse des moteurs.
   - ImplÃ©mentation des mouvements du robot : avancer, reculer, tourner Ã  gauche ou Ã  droite.

3. **Gestion des capteurs de bordure/dÃ©tection de chute**
   - Lecture des entrÃ©es des capteurs pour dÃ©tecter les bords de la table.
   - RÃ©action immÃ©diate pour stopper ou changer de direction afin dâ€™Ã©viter une chute.

4. **InterfaÃ§age avec le LiDAR YDLIDAR X4**
   - Communication via **UART** pour lire les donnÃ©es du LiDAR.
   - Extraction des valeurs dâ€™angles et de distances pour cartographier l'environnement et Ã©viter les obstacles.

---

## ğŸš€ **RÃ©alisation matÃ©rielle**  
La partie matÃ©rielle a Ã©tÃ© conÃ§ue avec **KiCad 8.0** et comprend :  
- ğŸ“œ **SchÃ©ma Ã©lectronique**  
- ğŸ§© **PCB routÃ©**  
- ğŸ› ï¸ **BOM (Bill of Materials)**  
- ğŸ—‚ï¸ **Fichiers GERBER** pour fabrication chez **JLCPCB**.  

Pour construire notre carte Ã©lectronique, il nous a fallut commencer par designer sous KiCad le schÃ©ma Ã©lectrique de notre systÃ¨me Ã©lectronique, ce que l'on appelle schematic dans KiCad. Nous allons maintenant dÃ©taillÃ© les diffÃ©rentes parties du schematic (les sheets du projet KiCad).

## SchÃ©ma Ã©lectronique ## 
#### Capteurs du robot #####

Le robot contient plusieurs capteurs, un capteur Time Of Flight TOF, un capteur LIDAR, et un capteur accÃ©lÃ©romÃ¨tre.

Le capteur TOF est un capteur de distance qui communique en I2C avec le cerveau du robot qu'est la stm32. L'avantage de cette communication est qu'elle permet une Ã©volutivitÃ© si on a besoin d'ajouter d'autres composants matÃ©riel par la suite. Seulement pour cela il faut prÃ©voir une rÃ©sistance de pull-up (tirage) pour le bus I2C.



Les signaux nÃ©cessaires pour implÃ©menter en I2C ce capteur sont les suivants : 

- SDA
- SCL
- int_tof1
- xshunt1
- GND

Ces signaux sont reprÃ©sentÃ©s sur le connecteur JST de la figure ci-dessous.

 

![image-20250113151649896](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/tof-image-20250113151649896.png)


Le capteur AccÃ©lÃ©romÃ¨tre  est un capteur qui communique lui en SPI, tout comme le capteur TOF , il utilise un bus de communication qui nÃ©cessite une rÃ©sistance de pull-up (tirage).

![image-20250114095447270](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/adx-image--20250114095447270.png) 

Les signaux nÃ©cessaires pour implÃ©menter en SPI ce capteur sont les suivants : 

- MISO

- MOSI

- SCK

- nCS

- Interruption nÂ°1 ADX

- Interruption nÂ°2 ADX

- +5V

- GND

  

  

Comme on peut le voir, pour des raisons CEM nous avons placÃ© une capacitÃ© de 1ÂµF et une capacitÃ© de 0.1 ÂµF pour dÃ©coupler les deux alimentations en +3.3V.

Afin de pouvoir dÃ©bugger le capteur, nous avons Ã©galement placÃ© des points de test TestPoint.



Le capteur LIDAR est un capteur qui communique par liason sÃ©rie UART dont les signaux sont les suivants :

![image-20250114095520915](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/lidar%20-image-lidar-20250114095520915.png)

- M_EN
- DEV_EN
- M_SCTR
- RX_lidar
- TX_lidar
- +5V
- GND



#### Motorisation du robot ####

Les composants qui s'assure dÃ©placer le robot sont les moteurs qui sont des mcc **FIT 0520.** 

Pour commander ces moteurs nous avons besoin de driver, ce sont eux qui vont envoyer les signaux de commande au moteur (des PWM). 

Les drivers utilisÃ©s sont les ZXBM5210-S-13. 

![image-driver20250114113650516](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/driver%20motor-%20image-20250114113650516.png)



Voici le schÃ©ma du composant. Les sorties out 1 et out 2  sont connectÃ©s au moteur  par Motor1+ et  Motor 1-.

Comme ce sont les signaux de commande PWM, nous avons dÃ©couplÃ© ces signaux avec des capacitÃ©s de 100nF.

Quant aux signaux d'alimentation nous dÃ©couplons la tension de la batterie avec une capacitÃ© de 10ÂµF pour le signal Vm et une capacitÃ© de 1ÂµF pour 



Le signal PWM_MOT1_CH1 est le signal PWM gÃ©nÃ©rÃ© par le STM32 en direction du pin FWD du composant .
Le signal PWM_MOT1_CH2 est le signal PWM gÃ©nÃ©rÃ© par le STM32  en direction du pin REV du composant.



D'aprÃ¨s le tableau de la datasheet, si on envoie un signal PWM pour contrÃ´ler le driver en mode "PWM control mode". 

Il faut alors envoyer un signal PWM en entrÃ© sur un des pins FWD ou REV. Ce qui donnera naissance Ã  un signal PWM en sortie sur out1-out2 de frÃ©quence Ã©gale Ã  celle en entrÃ©e du pin qui reÃ§oit le signal PWM.   
Comme nous avons deux moteurs, il faut deux drivers, voici le schÃ©ma du deuxiÃ¨me driver : 
![driver2](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/driver2_schema.png)


Pour obtenir la vitesse des roues, nous utilisons les encodeurs des moteurs. Pour cela il faut prÃ©parer, l'alimentation et les signaux dont ils ont besoin dans un connecteur (jst en l'occurrence).
  



D'aprÃ¨s la documentation des moteur/encodeurs, les signaux sont placÃ©s de la faÃ§on suivante sur le brochage : 

![signaux encodeurs](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/encodeur_signaux_sur_moteurs.png)

On peut lire sur cette image que les signaux de l'encodeur sont les suivants : 
 - alimentation 3V3
 - ground GND
 - codeurX_PH1 [pour la phase A]
 - codeurX_PH2 [pour la phase B]


Nous avons placÃ© ces signaux entre les deux signaux destinÃ©s au moteurs et conservÃ© l'ordre d'affectation des broches de la doumention, ce qui donne ce schÃ©ma de connector : 

![encodeurs](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/encodeurs_schema.png)


#### Le Cerveau du robot : le STM32 & cie #### 

Dans cette feuille, nous avons connecter les composants suivants, le STM32, le STlink, le Quartz, des leds, un bouton pour changer d'Ã©tat et un bouton NRST pour reset le STM32.
![brain_sheet](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/brain_sheet_only_page-0001.jpg)  

#####  le STM32  #####

rÃ©sistance de tirage bus I2C

dÃ©couplage alim stm32 Ã  dire 
#####  le quartz #####
dÃ©couplage OSC_In OSC_OUT du quartz 

#####  le STLink #####

#####  les boutons #####



### ğŸ”‘ [AccÃ©dez aux fichiers hardware ici.](./hardware/)

---

## ğŸ› ï¸ **DÃ©veloppement logiciel**  
Le logiciel embarquÃ© a Ã©tÃ© dÃ©veloppÃ© avec **STM32CubeIDE** et inclut :  
- ğŸ”§ **Configuration des pÃ©riphÃ©riques** (SPI, UART, PWM, etc.).  
- ğŸ“¦ **Modules logiciels** pour capteurs et moteurs.  
- ğŸ¤– **Algorithmes embarquÃ©s** pour les comportements du robot (poursuite, Ã©vitement, etc.).  

### ğŸ“‚ [AccÃ©dez au code source ici.](./Software)

---

## ğŸ‘¥ **Auteurs**  
- **Vincent LAKHMECHE**  
- **Mohamed Rafik CHAIR**  
- **Meziane Ameur**  
- **Karim JERJOUB**

---

## ğŸ“„ **Licence**  
ğŸ“ Ce projet est sous licence **MIT**.  
Pour plus dâ€™informations, consultez le fichier [LICENSE](./LICENSE).  


# ğŸš€ Explication sur l'utilisation de l'accÃ©lÃ©romÃ¨tre ADXL343 dans le robot chat


---

## ğŸ¯ Objectifs principaux
- âœ¨ **DÃ©tecter les tapotements** (Single Tap/Double Tap) pour **changer de rÃ´le** entre le robot "chat" et le robot "souris".
- ğŸ“Š Lire les valeurs d'accÃ©lÃ©ration sur les axes **X, Y, Z** *(optionnel)*.

---

## âš™ï¸ Configuration
- **Plage d'accÃ©lÃ©ration :** Â±2 g *(prÃ©cision pour petits mouvements)*.
- **Registres utilisÃ©s :**  
  - ğŸ› ï¸ `POWER_CTL` : Activer le mode mesure.  
  - ğŸšï¸ `THRESH_TAP`, `DUR`, `INT_ENABLE` : Configurer les seuils et activer les interruptions pour les tapotements.  
  - ğŸ–¥ï¸ `INT_SOURCE` : VÃ©rifier les Ã©vÃ©nements de tapotements.

---

## ğŸ”§ FonctionnalitÃ©s implÃ©mentÃ©es
### âœ… DÃ©tection des tapotements
- ğŸ”„ VÃ©rifie les interruptions via le registre `INT_SOURCE`.
- ğŸ“ Met Ã  jour la variable globale `tap_detected` pour signaler un Ã©vÃ©nement.

### âœ… Lecture des accÃ©lÃ©rations
- ğŸ“¥ RÃ©cupÃ©ration des valeurs brutes : `acc_rawX`, `acc_rawY`, `acc_rawZ`.
- ğŸ”„ Conversion des valeurs en unitÃ©s normalisÃ©es (*g*) via un facteur de calibration.

---

## ğŸ” RÃ©actions aux tapotements
- âš¡ **Interruptions activÃ©es** pour permettre une rÃ©action en temps rÃ©el.
- ğŸ”€ Chaque tapotement entraÃ®ne un **changement de comportement des moteurs** (ex. direction ou rÃ´le).

---

## ğŸ•’ FreeRTOS Task
- CrÃ©ation d'une tÃ¢che principale **`vTaskADX`** pour :  
  1ï¸âƒ£ Lire les donnÃ©es d'accÃ©lÃ©ration brutes et normalisÃ©es.  
  2ï¸âƒ£ VÃ©rifier les Ã©vÃ©nements de tapotement.  
  3ï¸âƒ£ Ajouter un dÃ©lai pour rÃ©duire la charge CPU (`vTaskDelay`).

---

# ContrÃ´le des Moteurs et Encodeurs

## ğŸ› ï¸ Composants utilisÃ©s

Liste des composants utilisÃ©s pour le projet robot avec leurs spÃ©cifications et leurs rÃ´les dans le systÃ¨me.

## ğŸš— Moteurs

Le contrÃ´le des moteurs est effectuÃ© Ã  l'aide d'un driver. Ce driver contient plusieurs fonctions pour contrÃ´ler la direction et la vitesse des moteurs du robot.

### FonctionnalitÃ©s du driver :

- **`void init_motors(void);`** : Initialisation des moteurs.
- **`void forward_r(uint16_t alpha);`** : Faire avancer le moteur droit.
- **`void forward_l(uint16_t alpha);`** : Faire avancer le moteur gauche.
- **`void reverse_r(uint16_t alpha);`** : Faire reculer le moteur droit.
- **`void reverse_l(uint16_t alpha);`** : Faire reculer le moteur gauche.
- **`void stop_r(void);`** : ArrÃªter le moteur droit.
- **`void stop_l(void);`** : ArrÃªter le moteur gauche.

### ğŸ”§ ConsidÃ©rations mÃ©caniques

![chassis Image 2025-01-13 Ã  14 57 42_cc206d9a](https://github.com/flexdrt/StealthKitty/blob/main/annexes/assets/repr%C3%A9sentation%20robot.png)



Le robot utilise deux moteurs, un pour chaque roue :

- La roue droite est en **rouge** et la roue gauche est en **bleue**.
- Les roues tournent dans des directions opposÃ©es pour permettre au robot de se dÃ©placer en avant ou en arriÃ¨re.


### ğŸ”„ Sens de marche
![aaa](https://github.com/user-attachments/assets/a936be50-3f89-4b7e-88a4-d89e8650bdf3)

| Moteur Gauche  | Sens de marche Robot | Moteur Droit |
| -------------- | -------------------- | ------------ |
| Sens **reverse** | Sens **forward** | Sens **forward** |

### ğŸš€ Fonctionnement des moteurs

#### 1. **Moteurs en marche forward**

Pour que le robot se dÃ©place en avant, les moteurs doivent tourner dans des directions opposÃ©es. Le code suivant configure le moteur droit et le moteur gauche pour aller en avant.

```c
// Fonction pour faire avancer le moteur droit
void forward_r(uint16_t alpha) {
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_1, alpha);  // TIM1_CH1
    HAL_TIM_PWM_Start(&htim1, TIM_CHANNEL_1);   // DÃ©marre la PWM pour le moteur droit
    HAL_TIMEx_PWMN_Stop(&htim1, TIM_CHANNEL_1); // ArrÃªte le canal complÃ©mentaire
}

// Fonction pour faire avancer le moteur gauche
void forward_l(uint16_t alpha) {
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_2, alpha);  // TIM1_CH2
    HAL_TIMEx_PWMN_Start(&htim1, TIM_CHANNEL_2);          // DÃ©marre la PWM pour le moteur gauche
}
```
#### 2. Moteurs en marche arriÃ¨re (Reverse)
Pour que le robot se dÃ©place en arriÃ¨re, les directions des moteurs doivent Ãªtre inversÃ©es :

```c
// Fonction pour faire reculer le moteur droit
void reverse_r(uint16_t alpha) {
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_2, alpha);  // Inverser le sens pour moteur droit
    HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_1);   // ArrÃªter le moteur droit
    HAL_TIMEx_PWMN_Start(&htim1, TIM_CHANNEL_1); // DÃ©marrer le moteur droit en reverse
}

// Fonction pour faire reculer le moteur gauche
void reverse_l(uint16_t alpha) {
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_1, alpha);  // Inverser le sens pour moteur gauche
    HAL_TIM_PWM_Start(&htim1, TIM_CHANNEL_2);   // DÃ©marrer le moteur gauche en reverse
}
```
#### 3. ArrÃªt des moteurs

On veut pouvoir stopper chaque moteurs individuellement. Pour stopper le moteur droit, on a coder cette fonction : 



****



***************************A supprimer****************



```C
// Fonction stop moteur droit
void stop_r(void) {
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_1, 0);      // TIM1_CH1
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_2, 0);     // TIM1_CH2N
    HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_1);   // TIM1_CH1N
    HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_2);   // TIM1_CH2

}
```



*********************************************************************************************

Avec la fonction HAL  [Version corrigÃ©]

```c
// Fonction stop moteur droit
void stop_r(void) {
    //__HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_1, 0);      // TIM1_CH1
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_2, 0);     // TIM1_CH2N
    //HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_1);   // TIM1_CH1N
    HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_2);   // TIM1_CH2

}
```

On met Ã  0 le compteur de la PWM du channel 2 et on stop la gÃ©nÃ©ration de PWM pour arrÃªter le moteur droit.



```c
// Fonction stop moteur gauche
void stop_l(void) {
    //__HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_2, 0);      // TIM1_CH2
    __HAL_TIM_SET_COMPARE(&htim1, TIM_CHANNEL_1, 0);     // TIM1_CH1N
    HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_1);   // TIM1_CH1N
    //HAL_TIM_PWM_Stop(&htim1, TIM_CHANNEL_2);   // TIM1_CH2
}
```

On met Ã  0 le compteur de la PWM du channel 1 et on stop la gÃ©nÃ©ration de PWM pour arrÃªter le moteur gauche.

### ğŸ”§ Encodeur
Les encodeurs sont utilisÃ©s pour mesurer la position des moteurs et calculer leur vitesse.

#### Fonctions d'encodeur
#### 1. Obtenir la position de l'encodeur
```c
// Fonction pour obtenir la position de l'encodeur
int16_t get_encoder_position(uint8_t motor) {
    int16_t position = 0;

    if (motor == MOTOR_LEFT) {
        position = __HAL_TIM_GET_COUNTER(&htim4);  // Lire le compteur du moteur gauche
    } else if (motor == MOTOR_RIGHT) {
        position = __HAL_TIM_GET_COUNTER(&htim3);  // Lire le compteur du moteur droit
    }

    return position;
}
```
#### 2. RÃ©initialiser la position de l'encodeur
```c
// Fonction pour rÃ©initialiser la position de l'encodeur
void reset_encoder(uint8_t motor) {
    if (motor == MOTOR_LEFT) {
        __HAL_TIM_SET_COUNTER(&htim4, 0);  // RÃ©initialiser le compteur du moteur gauche
    } else if (motor == MOTOR_RIGHT) {
        __HAL_TIM_SET_COUNTER(&htim3, 0);  // RÃ©initialiser le compteur du moteur droit
    }
}
```
#### 3. Calculer la vitesse des moteurs
```c
// Fonction pour calculer la vitesse Ã  partir de l'encodeur
float calculate_motor_speed(uint8_t motor, uint32_t delta_time_ms, uint16_t encoder_resolution) {
    static int16_t last_position_motor1 = 0;
    static int16_t last_position_motor2 = 0;

    int16_t current_position = 0;
    int16_t delta_position = 0;

    if (motor == MOTOR_LEFT) { // Moteur gauche
        current_position = __HAL_TIM_GET_COUNTER(&htim3); // TIM3 pour moteur gauche
        delta_position = current_position - last_position_motor1;
        last_position_motor1 = current_position;
    } else if (motor == MOTOR_RIGHT) { // Moteur droit
        current_position = __HAL_TIM_GET_COUNTER(&htim4); // TIM4 pour moteur droit
        delta_position = current_position - last_position_motor2;
        last_position_motor2 = current_position;
    }

    // Calcul de la vitesse en tours par seconde
    float speed = (float)delta_position / encoder_resolution; // Tours par intervalle
    speed *= (1000.0f / delta_time_ms); // Convertir en tours par seconde

    return speed;
}
```



Cette fonction calcule la vitesse des moteurs Ã  partir de la diffÃ©rence avec la derniÃ¨re position et la rÃ©solution de l'encodeur (1024). Puis on convertit en tours par seconde.



# ğŸš€ Utilisation du YDLIDAR X4 dans le robot

**ğŸ¯ CaractÃ©ristiques techniques**
* ğŸ“¡ **Range Frequency :** 5000Hz
* ğŸ“ **Range Distance :** 0.12-10m 
* ğŸ“ **Angle Resolution :** 0.43-0.86Â°
* ğŸ”„ **Scan Frequency :** 6-12Hz
* ğŸŒŸ **Scan Angle :** 360Â°
* ğŸ“¦ **Size :** Î¦65.6 * 58.39 * 101.7mm

**âš™ï¸ Communication et trames**
* ğŸ”Œ **Interface :** UART (DMA)
* ğŸ“¦ **Structure des trames :**
  * ğŸ Start Sign : 0xA5 0x5A
  * ğŸ“Š Package Length
  * ğŸ” Mode & Type Code
  * ğŸ“ FSA (First Scan Angle)
  * ğŸ“ LSA (Last Scan Angle)
  * âœ… CS (Checksum)
  * ğŸ“ Packet Data

**ğŸ”§ Traitement des donnÃ©es**
* **Parser de trames :**
```c
if(i==frame_start){
    dev_handle.processing.PH=dev_handle.raw_data[i];
} else if(i==frame_start+1){
    dev_handle.processing.PH |= (dev_handle.raw_data[i]<<8);
}
// etc...
```

**ğŸ“Š Analyse des donnÃ©es**
* ğŸ” **DÃ©tection d'objets :**
  * Filtrage des distances (0-2000mm)
  * Calcul des centres de masse (assimilable Ã   du clustering de points par paquets)
  * Identification des clusters
* ğŸ¯ **Tracking :**
  * Suivi de l'objet le plus proche
  * Calcul angle moyen et distance

------

**ğŸ’¾ Structure de donnÃ©es**
```c
typedef struct data_proc_struct {
    uint16_t PH;        // Package Header
    uint8_t CT;         // Package Type
    uint8_t LSN;        // Sample Quantity
    uint16_t FSA;       // First Scan Angle
    uint16_t LSA;       // Last Scan Angle
    uint16_t CS;        // CheckSum
    // etc...
} data_proc_t;
```

**âš¡ Performances**
* ğŸ”„ **Temps rÃ©el :** Acquisition et traitement via DMA pour ne pas saturÃ© la RAM
* ğŸ“Š **RÃ©solution :** ~0.5Â° en rotation
* ğŸ“ **PrÃ©cision distance :** Â±1% sur plage optimale
* â±ï¸ **Latence :** <100ms pour dÃ©tection et rÃ©action(idÃ©alement)

**ğŸ” Cycle de fonctionnement**
1. ğŸ“¡ RÃ©ception trame DMA
2. ğŸ” Validation checksum et headers
3. ğŸ“Š Parsing des donnÃ©es
4. ğŸ¯ DÃ©tection objets et calcul distances
5. ğŸ® Application asservissement moteurs vu ultÃ©rieurement

**ğŸ› ï¸ Fonctions clÃ©s du driver**
```c
sns_begin()        // DÃ©marrage acquisition
sns_parse_data()   // Traitement trame
smooth_data()      // Filtrage donnÃ©es
detect_objects()   // DÃ©tection objets
```

**âš ï¸ Points critiques**
* Gestion buffer circulaire DMA
* Validation intÃ©gritÃ© trames
* Filtrage donnÃ©es aberrantes
* Asservissement progressif dÃ©taillÃ© ultÃ©rieurement



## ğŸ•’ FreeRTOS Task du LIDAR

â€‹     

- ## ğŸ“¦ DÃ©tection et Validation En-tÃªte (i==0)

  - VÃ©rification sÃ©quence 7 octets :

    - 0xA5 0x5A (Start Sign)
    - 0x05 0x00
    - 0x00 0x40
    - 0x81

    

  ## ğŸ“ Parsing de Trame (Machine Ã  Ã‰tats)

  - frame_start : Package Header bas
  - frame_start+1 : Package Header haut
  - frame_start+2 : Type de paquet
  - frame_start+3 : Nombre d'Ã©chantillons
  - frame_start+4/5 : Angle de dÃ©but (FSA)
  - frame_start+6/7 : Angle de fin (LSA)
  - frame_start+8/9 : Checksum

  

  ## ğŸ¯ Traitement des DonnÃ©es

  - Si fin de trame (i==frame_end) :

    - Stockage derniÃ¨re donnÃ©e
    - Parse des donnÃ©es brutes
    - Lissage des donnÃ©es
    - DÃ©tection des objets
    - Reset des index pour trame suivante

    

  ## ğŸ“Š Analyse Finale

  - Recherche de l'objet le plus proche :

    - Distance minimale non nulle
    - Mise Ã  jour dist_min et idx_min

  - Affichage donnÃ©es :

    - Pour chaque objet : angle et distance
    - DÃ©tails de l'objet le plus proche

    

  ## âš™ï¸ Gestion des Indices

  - Ajustement frame_start et frame_end
  - Gestion du buffer circulaire
  - Maintien de la synchronisation des trames





# ThÃ©orie de l'asservissement angulaire du robot

## 1. DÃ©finition du systÃ¨me

### Variables d'Ã©tat
- Î¸_mesure : Angle mesurÃ© par le LIDAR du cluster le plus proche (en degrÃ©s)
- Î¸_consigne : Angle dÃ©sirÃ© (0Â° dans notre cas)
- e(t) : Erreur en angle
- u(t) : Signal de commande (correction)
- v_g : Vitesse du moteur gauche
- v_d : Vitesse du moteur droit

### Ã‰quations fondamentales

1. Calcul de l'erreur :
```
e(t) = Î¸_consigne - Î¸_mesure
```

2. Loi de commande proportionnelle :
```
u(t) = Kp Ã— e(t)
```
oÃ¹ Kp est le gain proportionnel

3. Vitesses des moteurs :
```
v_g = v_base + u(t)
v_d = v_base - u(t)
```
oÃ¹ v_base est la vitesse nominale

## 2. Normalisation de l'angle

Pour avoir un comportement symÃ©trique, l'angle mesurÃ© est normalisÃ© dans l'intervalle [-180Â°, 180Â°] :
```
Si Î¸_mesure > 180Â° :
    Î¸_normalisÃ© = Î¸_mesure - 360Â°
Sinon :
    Î¸_normalisÃ© = Î¸_mesure
```

## 3. Fonction de transfert

Dans le domaine de Laplace, la fonction de transfert du systÃ¨me peut Ãªtre approximÃ©e par :

```
G(s) = K / (1 + Ï„s)
```
oÃ¹ :
- K est le gain statique du systÃ¨me
- Ï„ est la constante de temps du systÃ¨me
- s est la variable de Laplace



## 4. StabilitÃ© du systÃ¨me

Le systÃ¨me en boucle fermÃ©e a une fonction de transfert :
```
H(s) = (K Ã— Kp) / (1 + Ï„s + K Ã— Kp)
```

La stabilitÃ© est assurÃ©e si :
```
0 < Kp < 1/(K Ã— Ï„)
```



## 5. ConsidÃ©rations de mise en Å“uvre

1. Choix du gain Kp :
- Trop faible : rÃ©ponse lente
- Trop Ã©levÃ© : oscillations
- Optimal : compromis entre rapiditÃ© et stabilitÃ©



**Conversion en commandes moteurs** (alpha1 et alpha2) :

- Si la cible est Ã  droite :

  - On augmente la vitesse du moteur gauche (alpha1)

  - On diminue la vitesse du moteur droit (alpha2)

    â†’ Le robot tourne Ã  droite



- Si la cible est Ã  gauche :

  - On augmente la vitesse du moteur droit (alpha2)

  - On diminue la vitesse du moteur gauche (alpha1)

    â†’ Le robot tourne Ã  gauche



A dÃ©faut d'un fonctionnement asservi en vitesse de nos moteurs, nous n'avons pas pu tester cet asservissement angulaire sur notre robot bien qu'une Ã©bauche du code soit implÃ©mentÃ©e dans la tache du Lidar TaskLIDAR.









 



